<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
    <title>LLM4AD|Purdue Digital Twin Lab</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <link rel="icon" href="images/icon_36_36.png" />
    <noscript>
        <link rel="stylesheet" href="assets/css/noscript.css" />
    </noscript>
</head>

<body class="is-preload">

    <!-- Wrapper -->
    <div id="wrapper" class="fade-in">

        <!-- Intro -->
        <div id="intro">
            <h1>Large Language Models for Autonomous Driving <br />
                (LLM4AD)<br /></h1>
            <h2><span class="image left"><img src="images/purdue_logo.png" height="30" alt="" /></span>
                </hr><a href="https://purduedigitaltwin.github.io/">Purdue Digital Twin Lab<br /></a>
            </h2>
            <!-- <h2>Purdue Digital Twin Lab</h2> -->
            <!--        <p>Welcome to the forefront of innovation where language meets autonomous driving.-->
            <!--            Our website is a hub for the latest research, breakthroughs, and discussions in this area from Purdue-->
            <!--            Digital Twin Lab.</p>-->
            <ul class="actions">
                <li><a href="#header" class="button icon solid solo fa-arrow-down scrolly">Continue</a></li>
            </ul>
        </div>

        <!-- Header -->
        <header id="header">
            <a href="index.html" class="logo">LLM4AD</a>
        </header>


        <!-- Nav -->
        <nav id="nav">
            <ul class="links">
                <li class="active"><a href="index.html">Overview</a></li>
                <li><a href="talk2drive.html">Talk2Drive</a></li>
                <li><a href="3R.html">3R</a></li>
                <li><a href="survey.html">Survey</a></li>
                <li><a href="lampilot.html">LaMPilot</a></li>
                <li><a href="lhf.html">LHF</a></li>
            </ul>
        </nav>

        <!-- Main -->
        <div id="main">

            <!-- Featured Post -->
            <article class="post featured">
                <header class="major">
                    <!-- <span class="date">April 25, 2017</span> -->
                    <h2><a href="#">Our Goal<br /></a></h2>
                    <p> Our work focuses on pioneering research at the intersection of LLMs, VLMs and autonomous
                        driving.
                        We're investigating how advanced language understanding can improve vehicle decision-making and
                        human-vehicle interaction, thereby enhancing safety and efficiency in autonomous systems. Our
                        goal
                        is to push the boundaries of AI in automotive technology and lead the way in developing smarter,
                        safer, and more intuitive autonomous vehicles for the future.<br /></p>
                </header>


                <!--            <header>-->
                <!--                <p>Main Areas:<br/>-->
                <!--                    1. Developing and implementing LLM-based frameworks specifically tailored for autonomous-->
                <!--                    driving.<br/>-->
                <!--                    2. Actual deployment of our LLM-based frameworks in real-world vehicles to test and refine their-->
                <!--                    capabilities.<br/>-->
                <!--                    3. Improving human-machine interfaces to create more intuitive and user-friendly interactions in-->
                <!--                    autonomous vehicles. <br/>-->
                <!--                    4. Enhancing the personalized autonomous driving system using LLM-based frameworks.<br/>-->
                <!--                    5. Maintaining a steadfast commitment to safety in all our innovations, ensuring reliable and-->
                <!--                    secure advancements in autonomous driving technology. <br/>-->
                <!--                </p>-->
                <!--            </header>-->
            </article>

            <!-- Posts -->
            <section class="posts">
                <article>
                    <header>
                        <span class="date">February 27, 2024</span>
                        <h2><a href="#">One Paper was Accepted @CVPR 2024 !<br /></h2>
                    </header>
                    <a href="#" class="image fit"><img src="images/lampilot.png" alt="" /></a>
                    <p> Our paper
                        "LamPilot: An open benchmark dataset for autonomous driving with language model programs" was
                        accepted by CVPR 2024!
                    </p>
                    <ul class="actions special">
                        <li>
                            <a href="https://arxiv.org/abs/2312.04372" class="button">Paper</a>
                        </li>
                    </ul>
                </article>

                <article>
                    <header>
                        <span class="date">February 27, 2024</span>
                        <h2><a href="#">One Paper was Accpeted @CVPR 2024 !<br /></h2>
                    </header>
                    <a href="#" class="image fit"><img src="images/maplm.jpg" alt="" /></a>
                    <p> Our paper
                        "MAPLM: A Real-World Large-Scale Vision-Language Dataset for Map and Traffic Scene
                        Understanding" was accepted by CVPR 2024!
                    </p>
                    <!-- <ul class="actions special">
                        <li>
                            <a href="https://arxiv.org/abs/2312.04372"
                                class="button">Paper</a>
                        </li>
                    </ul> -->
                </article>

                <article>
                    <header>
                        <span class="date">January 20, 2024</span>
                        <h2><a href="#">Talk2Drive Featured video is Available <br /></a></h2>
                    </header>
                    <a href="#" class="image fit"><img src="images/cover(1).png" alt="" /></a>
                    <p>We released the featured video of our Talk2Drive framework. This is a condensed video for the
                        previous parking, intersection and highway scenarios, providing an overview of the features
                        within our Talk2Drive framework. </p>
                    <ul class="actions special">
                        <li><a href="https://www.youtube.com/watch?v=4BWsfPaq1Ro" class="button">Demos</a></li>
                    </ul>
                </article>
                <article>
                    <header>
                        <span class="date">January 20, 2024</span>
                        <h2><a href="#">Parking Demos are Available <br /></a></h2>
                    </header>
                    <a href="#" class="image fit"><img src="images/parking.png" alt="" /></a>
                    <p>We successfully used our Talk2Drive framework in the parking scenario, and new demos were
                        available now! </p>
                    <ul class="actions special">
                        <li><a href="https://www.youtube.com/watch?v=_nRmJjIS0pM&t=141s" class="button">Demos</a></li>
                    </ul>
                </article>
                <article>
                    <header>
                        <span class="date">December 22, 2023</span>
                        <h2><a href="#">Highway Demos are Available <br /></a></h2>
                    </header>
                    <a href="#" class="image fit"><img src="images/high.png" alt="" /></a>
                    <p>We successfully used our Talk2Drive framework in the highway scenario, and new demos were
                        available now! </p>
                    <ul class="actions special">
                        <li><a href="https://www.youtube.com/watch?v=mJk_Ru4Atjc" class="button">Demos</a></li>
                    </ul>
                </article>
                <article>
                    <header>
                        <span class="date">December 22, 2023</span>
                        <h2><a href="#">Intersection Demos are Available<br /></a></h2>
                    </header>
                    <a href="#" class="image fit"><img src="images/inter.png" alt="" /></a>
                    <p>We successfully used our Talk2Drive framework in the intersection scenario, and new demos were
                        available now!</p>
                    <ul class="actions special">
                        <li><a href="https://www.youtube.com/watch?v=KlJ_dHuEkwI&t=1s" class="button">Demos</a></li>
                    </ul>
                </article>
                <article>
                    <header>
                        <span class="date">December 14, 2023</span>
                        <h2><a href="#">Real-world Implementation paper (Talk2Drive) !<br /></h2>
                    </header>
                    <a href="#" class="image fit"><img src="images/arxiv.png" alt="" /></a>
                    <p>Our new paper "Large Language Models for Autonomous Driving: Real-World Experiments" about
                        Talk2Drive was available now!</p>
                    <ul class="actions special">
                        <li><a href="https://arxiv.org/abs/2312.09397" class="button">Arxiv</a></li>
                    </ul>
                </article>
                <article>
                    <header>
                        <span class="date">Decmember 7, 2023</span>
                        <h2><a href="#">One new Benchmark (LaMPilot)!<br /></h2>
                    </header>
                    <a href="#" class="image fit"><img src="images/lampilot.png" alt="" /></a>
                    <p> Our new benchmark paper
                        "LaMPilot: An Open Benchmark Dataset for Autonomous Driving with Language Model Programs" was
                        avaliable now!</p>
                    <ul class="actions special">
                        <li><a href="https://arxiv.org/abs/2312.04372" class="button">Arxiv</a></li>
                    </ul>
                </article>
                <article>
                    <header>
                        <span class="date">November 23, 2023</span>
                        <h2><a href="#">Talk2Drive Parking lot Test<br /></h2>
                    </header>
                    <a href="#" class="image fit"><img src="images/start_p.png" alt="" /></a>
                    <p> We successfully tested our Talk2Drive framework on a real vehicle in a closed parking lot.
                    </p>
                    <ul class="actions special">
                        <li><a href="https://www.youtube.com/watch?v=RY8Rdt0Sobk" class="button">Demos</a></li>
                    </ul>
                </article>
                <article>
                    <header>
                        <span class="date">November 23, 2023</span>
                        <h2><a href="#">One Paper (Survey) was Accepted @WACV 2024 !<br /></h2>
                    </header>
                    <a href="#" class="image fit"><img src="images/workflow_survey.png" alt="" /></a>
                    <p> Our new paper
                        "A Survey on Multimodal Large Language Models for Autonomous Driving" was accepted by WACV 2024!
                    </p>
                    <ul class="actions special">
                        <li><a href="https://openaccess.thecvf.com/content/WACV2024W/LLVM-AD/html
											/Cui_A_Survey_on_Multimodal_Large_Language_Models_for_Autonomous_Driving_WACVW_2024_paper.html"
                                class="button">Paper</a></li>
                    </ul>
                </article>
                <article>
                    <header>
                        <span class="date">November 23, 2023</span>
                        <h2><a href="#">One Framework Paper was Accpeted @WACV 2024 !<br /></h2>
                    </header>
                    <a href="#" class="image fit"><img src="images/framework.png" alt="" /></a>
                    <p> Our new paper
                        "Drive as You Speak: Enabling Human-Like Interaction with Large Language Models in Autonomous
                        Driving" was accepted by WACV 2024!
                    </p>
                    <ul class="actions special">
                        <li>
                            <a href="https://openaccess.thecvf.com/content/WACV2024W/LLVM-AD/html/Cui_Drive_As_You_Speak_Enabling_Human-Like_Interaction_With_Large_Language_WACVW_2024_paper.html"
                                class="button">Paper</a>
                        </li>
                    </ul>
                </article>

                <article>
                    <header>
                        <span class="date">October 12, 2023</span>
                        <h2><a href="#">New simulation-based Paper (3R)!<br /></h2>
                    </header>
                    <a href="#" class="image fit"><img src="images/highway.png" alt="" /></a>
                    <p> Our new paper
                        "Receive, Reason, and React: Drive as You Say with Large Language Models in Autonomous Vehicles"
                        was avaliable now!</p>
                    <ul class="actions special">
                        <li><a href="https://arxiv.org/abs/2310.08034" class="button">Arxiv</a></li>
                    </ul>
                </article>
            </section>
        </div>
        <div id="copyright">
            <ul>
                <li>&copy; Purdue DIgital Twin Lab</li>
                <li>Lab Website: <a href="https://purduedigitaltwin.github.io">purduedigitaltwin.github.io</a></li>
            </ul>
        </div>
    </div>

    <!-- Scripts -->
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.scrollex.min.js"></script>
    <script src="assets/js/jquery.scrolly.min.js"></script>
    <script src="assets/js/browser.min.js"></script>
    <script src="assets/js/breakpoints.min.js"></script>
    <script src="assets/js/util.js"></script>
    <script src="assets/js/main.js"></script>

</body>

</html>